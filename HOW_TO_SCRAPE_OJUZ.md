# OJ.UZ –ë“Æ–ì–î–ò–ô–ì –•–≠–†–•–≠–ù –¢–ê–¢–ê–• –í–≠?

–ë–∏ —Ç–∞–Ω–¥ 4 –∞—Ä–≥–∞ –∑–∞–∞–∂ ”©–≥—å–µ - —Ö–∞–º–≥–∏–π–Ω —Ö—è–ª–±–∞—Ä–∞–∞—Å —ç—Ö–ª—ç—ç–¥:

---

## ü•á –ê–†–ì–ê 1: GitHub-–∞–∞—Å –±—ç–ª—ç–Ω –¥–∞—Ç–∞–≥ —Ç–∞—Ç–∞—Ö (–•–ê–ú–ì–ò–ô–ù –•–Ø–õ–ë–ê–†!)

–ê–ª—å —Ö—ç–¥–∏–π–Ω –±—ç–ª—ç–Ω –±–∞–π–≥–∞–∞ OI Checklist repositories-—É—É–¥–∞–∞—Å —Ç–∞—Ç–∞–∂ –∞–≤–∞—Ö.

### –ê–ª—Ö–∞–º 1: JSON —Ñ–∞–π–ª —Ç–∞—Ç–∞—Ö

–¢–µ—Ä–º–∏–Ω–∞–ª –¥—ç—ç—Ä –¥–∞—Ä–∞–∞—Ö –∫–æ–º–∞–Ω–¥—É—É–¥—ã–≥ –∞–∂–∏–ª–ª—É—É–ª:

```bash
# –ê–ª—å –Ω—ç–≥–∏–π–≥ —Å–æ–Ω–≥–æ–Ω–æ —É—É:

# –°–æ–Ω–≥–æ–ª—Ç 1: labs-asterisk version
wget https://raw.githubusercontent.com/labs-asterisk/oichecklist/main/src/data/problem_data.json

# –°–æ–Ω–≥–æ–ª—Ç 2: avighnac version (–∏–ª“Ø“Ø —à–∏–Ω—ç)
# –≠–Ω—ç repository –Ω—å –∏–ª“Ø“Ø –æ–ª–æ–Ω –º—ç–¥—ç—ç–ª—ç–ª—Ç—ç–π
```

### –ê–ª—Ö–∞–º 2: JSON-–æ–æ—Å oj.uz –±–æ–¥–ª–æ–≥—É—É–¥—ã–≥ –≥–∞—Ä–≥–∞—Ö

```bash
# –ó”©–≤—Ö”©–Ω oj.uz —Ö–æ–ª–±–æ–æ—Å—É—É–¥ –≥–∞—Ä–≥–∞—Ö
cat problem_data.json | grep '"link"' | grep 'oj.uz' | sed 's/.*view\///' | sed 's/".*//' > oj_uz_aliases.txt

# –≠—Å–≤—ç–ª Python –∞—à–∏–≥–ª–∞—Ö:
python3 << 'EOF'
import json

with open('problem_data.json', 'r') as f:
    data = json.load(f)

aliases = []

# JSON structure-—ç—ç—Å –±–æ–¥–ª–æ–≥—É—É–¥ —Ç“Ø“Ø—Ö
for section in data:
    if 'years' in section:
        for year in section['years']:
            if 'problems' in year:
                for prob in year['problems']:
                    if 'link' in prob and 'oj.uz' in prob['link']:
                        alias = prob['link'].split('/')[-1]
                        aliases.append(alias)

# –§–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö
with open('oj_uz_all_aliases.txt', 'w') as f:
    for alias in aliases:
        f.write(f"{alias}\n")

print(f"‚úÖ {len(aliases)} –±–æ–¥–ª–æ–≥–æ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
EOF
```

**–î–∞–≤—É—É —Ç–∞–ª:** –•–∞–º–≥–∏–π–Ω —Ö—è–ª–±–∞—Ä, —É–¥–∞–∞–Ω “Ø—Ä–≥—ç–ª–∂–ª—ç—Ö–≥“Ø–π  
**–°—É–ª —Ç–∞–ª:** –ó–∞—Ä–∏–º —à–∏–Ω—ç –±–æ–¥–ª–æ–≥—É—É–¥ –±–∞–π—Ö–≥“Ø–π –±–∞–π–∂ –±–æ–ª–Ω–æ

---

## ü•à –ê–†–ì–ê 2: Browser Console –∞—à–∏–≥–ª–∞—Ö (–•—É—Ä–¥–∞–Ω!)

### –ê–ª—Ö–∞–º 1: Browser –Ω—ç—ç—Ö

1. Chrome —ç—Å–≤—ç–ª Firefox –¥—ç—ç—Ä `https://oj.uz/problems` –Ω—ç—ç
2. `F12` –¥–∞—Ä–∂ Developer Tools –Ω—ç—ç
3. **Console** —Ç–∞–± —Ä—É—É –æ—á

### –ê–ª—Ö–∞–º 2: JavaScript –∫–æ–¥ –∞–∂–∏–ª–ª—É—É–ª–∞—Ö

–î–æ–æ—Ä—Ö –∫–æ–¥—ã–≥ Console-–¥Î∂ôÏó¨ÎÑ£Í∏∞—Ö–∏–π–∂ Enter –¥–∞—Ä:

```javascript
// –ù—ç–≥ —Ö—É—É–¥–∞—Å–Ω—ã –±–æ–¥–ª–æ–≥—É—É–¥ —Ü—É–≥–ª—É—É–ª–∞—Ö
let problems = [];
document.querySelectorAll('table tbody tr').forEach(row => {
    let cells = row.querySelectorAll('td');
    if (cells.length > 0) {
        let alias = cells[0].textContent.trim();
        if (alias && !alias.includes('Alias')) {
            problems.push(alias);
        }
    }
});

// “Æ—Ä –¥“Ø–Ω —Ö–∞—Ä—É—É–ª–∞—Ö
console.log('‚úÖ ' + problems.length + ' –±–æ–¥–ª–æ–≥–æ –æ–ª–¥–ª–æ–æ:');
console.log(problems.join('\n'));

// Clipboard-—Ä—É—É –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ö—É—É–ª–∞—Ö
copy(problems.join('\n'));
alert('‚úÖ ' + problems.length + ' –±–æ–¥–ª–æ–≥–æ clipboard-—Ä—É—É —Ö—É—É–ª–∞–≥–¥–ª–∞–∞!\nCtrl+V –¥–∞—Ä–∂ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–Ω–∞ —É—É.');
```

### –ê–ª—Ö–∞–º 3: –ë“Ø—Ö —Ö—É—É–¥—Å—É—É–¥—ã–≥ –¥–∞–≤—Ç–∞—Ö

–î–∞—Ä–∞–∞—Ö –∫–æ–¥—ã–≥ –∞–∂–∏–ª–ª—É—É–ª–∂ **–ë“Æ–•** —Ö—É—É–¥—Å—ã–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –¥–∞–≤—Ç–∞–Ω–∞:

```javascript
// –ë“Æ–• —Ö—É—É–¥—Å—ã–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä scrape —Ö–∏–π—Ö
async function scrapeAllPages() {
    let allProblems = [];
    let currentPage = 1;
    let maxPages = 57; // oj.uz –¥—ç—ç—Ä ~57 —Ö—É—É–¥–∞—Å –±–∞–π–¥–∞–≥
    
    console.log('üîÑ –ë“Ø—Ö —Ö—É—É–¥–∞—Å scrape —Ö–∏–π–∂ –±–∞–π–Ω–∞...');
    
    for (let page = 1; page <= maxPages; page++) {
        try {
            let url = page === 1 ? '/problems' : `/problems?page=${page}`;
            
            // Fetch page
            let response = await fetch(url);
            let html = await response.text();
            let parser = new DOMParser();
            let doc = parser.parseFromString(html, 'text/html');
            
            // Extract aliases
            let rows = doc.querySelectorAll('table tbody tr');
            rows.forEach(row => {
                let cells = row.querySelectorAll('td');
                if (cells.length > 0) {
                    let alias = cells[0].textContent.trim();
                    if (alias && !alias.includes('Alias')) {
                        allProblems.push(alias);
                    }
                }
            });
            
            console.log(`‚úì –•—É—É–¥–∞—Å ${page}/${maxPages}: ${rows.length} –±–æ–¥–ª–æ–≥–æ`);
            
            // Be nice to the server
            await new Promise(resolve => setTimeout(resolve, 500));
            
        } catch (error) {
            console.error(`‚úó –•—É—É–¥–∞—Å ${page} –¥—ç—ç—Ä –∞–ª–¥–∞–∞:`, error);
        }
    }
    
    console.log('\n' + '='.repeat(60));
    console.log(`‚úÖ –î–£–£–°–°–ê–ù! –ù–∏–π—Ç ${allProblems.length} –±–æ–¥–ª–æ–≥–æ`);
    console.log('='.repeat(60));
    console.log(allProblems.join('\n'));
    
    // Clipboard-—Ä—É—É —Ö—É—É–ª–∞—Ö
    copy(allProblems.join('\n'));
    
    // File —Ç–∞—Ç–∞—Ö (browser –¥—ç—ç—Ä)
    let blob = new Blob([allProblems.join('\n')], {type: 'text/plain'});
    let link = document.createElement('a');
    link.href = URL.createObjectURL(blob);
    link.download = 'oj_uz_all_problems.txt';
    link.click();
    
    alert('‚úÖ –î—É—É—Å–ª–∞–∞! ' + allProblems.length + ' –±–æ–¥–ª–æ–≥–æ\n–§–∞–π–ª —Ç–∞—Ç–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞...');
    
    return allProblems;
}

// –ê–∂–∏–ª–ª—É—É–ª–∞—Ö
scrapeAllPages();
```

**‚è±Ô∏è –•—É–≥–∞—Ü–∞–∞:** ~30 —Å–µ–∫—É–Ω–¥ (57 —Ö—É—É–¥–∞—Å √ó 0.5 —Å–µ–∫/—Ö—É—É–¥–∞—Å)  
**–î–∞–≤—É—É —Ç–∞–ª:** –•—É—Ä–¥–∞–Ω, –±“Ø—Ä—ç–Ω –∂–∞–≥—Å–∞–∞–ª—Ç  
**–°—É–ª —Ç–∞–ª:** Browser –Ω—ç—ç–ª—Ç—Ç—ç–π –±–∞–π—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π

---

## ü•â –ê–†–ì–ê 3: Python Script (–ü—Ä–æ–≥—Ä–∞–º–º—á–ª–∞–ª—ã–Ω –∞—Ä–≥–∞)

### –ê–ª—Ö–∞–º 1: Dependencies —Å—É—É–ª–≥–∞—Ö

```bash
pip install beautifulsoup4 requests
```

### –ê–ª—Ö–∞–º 2: Script “Ø“Ø—Å–≥—ç—Ö

`scrape_ojuz.py` —Ñ–∞–π–ª “Ø“Ø—Å–≥—ç—ç–¥ –¥–æ–æ—Ä—Ö –∫–æ–¥—ã–≥ —Ö—É—É–ª:

```python
#!/usr/bin/env python3
import requests
from bs4 import BeautifulSoup
import time

def scrape_all_ojuz():
    all_problems = []
    base_url = "https://oj.uz/problems"
    
    print("üîÑ Scraping oj.uz...")
    
    # –ù–∏–π—Ç —Ö—É—É–¥–∞—Å–Ω—ã —Ç–æ–æ–≥ –æ–ª–æ—Ö
    response = requests.get(base_url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Pagination links —à–∞–ª–≥–∞—Ö
    max_page = 57  # Default
    
    # –ë“Ø—Ö —Ö—É—É–¥—Å—ã–≥ –¥–∞–≤—Ç–∞—Ö
    for page in range(1, max_page + 1):
        url = f"{base_url}?page={page}" if page > 1 else base_url
        
        try:
            print(f"  –•—É—É–¥–∞—Å {page}/{max_page}...", end=" ")
            response = requests.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            table = soup.find('table')
            if table:
                rows = table.find_all('tr')[1:]  # Skip header
                count = 0
                
                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) >= 1:
                        alias = cols[0].text.strip()
                        if alias:
                            all_problems.append(alias)
                            count += 1
                
                print(f"‚úì {count} –±–æ–¥–ª–æ–≥–æ")
            
            time.sleep(0.5)  # Be nice to server
            
        except Exception as e:
            print(f"‚úó –ê–ª–¥–∞–∞: {e}")
    
    return all_problems

if __name__ == "__main__":
    problems = scrape_all_ojuz()
    
    # –§–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö
    with open('oj_uz_all_problems.txt', 'w') as f:
        for p in problems:
            f.write(f"{p}\n")
    
    print(f"\n‚úÖ {len(problems)} –±–æ–¥–ª–æ–≥–æ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
    print("üìÑ –§–∞–π–ª: oj_uz_all_problems.txt")
```

### –ê–ª—Ö–∞–º 3: –ê–∂–∏–ª–ª—É—É–ª–∞—Ö

```bash
python3 scrape_ojuz.py
```

**‚è±Ô∏è –•—É–≥–∞—Ü–∞–∞:** ~30-60 —Å–µ–∫—É–Ω–¥  
**–î–∞–≤—É—É —Ç–∞–ª:** –ê–≤—Ç–æ–º–∞—Ç–∂—É—É–ª–∞–ª—Ç, –¥–∞–≤—Ç–∞–∂ –∞–∂–∏–ª–ª—É—É–ª–∂ –±–æ–ª–Ω–æ  
**–°—É–ª —Ç–∞–ª:** Python dependencies —Ö—ç—Ä—ç–≥—Ç—ç–π

---

## üèÖ –ê–†–ì–ê 4: Manual —Ö—É—É–ª–∞—Ö (–•–∞–º–≥–∏–π–Ω –Ω–∞–π–¥–≤–∞—Ä—Ç–∞–π)

### –•—ç—Ä—ç–≤ –±“Ø—Ö –∞–≤—Ç–æ–º–∞—Ç –∞—Ä–≥–∞ –∞–∂–∏–ª–ª–∞—Ö–≥“Ø–π –±–æ–ª:

1. **oj.uz/problems** —Ä—É—É –æ—á
2. –•—É—É–¥–∞—Å —Ç—É—Å –±“Ø—Ä—ç—ç—Ä –Ω—ç—ç (page=1, page=2, ...)
3. –ë–æ–¥–ª–æ–≥—É—É–¥—ã–Ω –Ω—ç—Ä–∏–π–≥ text editor –¥—ç—ç—Ä —Ö—É—É–ª–∞—Ö
4. 57 —Ö—É—É–¥–∞—Å —Ö“Ø—Ä—Ç—ç–ª –¥–∞–≤—Ç–∞—Ö

**–≠—Å–≤—ç–ª:**

- OI Checklist webapp –∞—à–∏–≥–ª–∞—Ö: https://checklist.spoi.org.in/
- Manual export —Ö–∏–π—Ö

---

## üéØ –¢–∞ —é—É–≥ —Ö“Ø—Å—ç–∂ –±–∞–π–Ω–∞?

–ë–∏ —Ç–∞–Ω–¥ **–æ–¥–æ–æ** —è–≥ —é—É–≥ —Ö–∏–π–∂ ”©–≥”©—Ö–∏–π–≥ —Ö“Ø—Å—á –±–∞–π–Ω–∞ –≤—ç?

**A)** GitHub-–∞–∞—Å –±—ç–ª—ç–Ω –¥–∞—Ç–∞–≥ —Ç–∞—Ç–∞–∂ ”©–≥”©—Ö (5 —Å–µ–∫)  
**B)** Browser console –∫–æ–¥ ”©–≥”©—Ö (1 –º–∏–Ω—É—Ç)  
**C)** Python script ”©–≥”©—Ö (–±—ç–ª—ç–Ω –±–æ–ª—Å–æ–Ω)  
**D)** –ë–∏ ”©”©—Ä”©”© scrape —Ö–∏–π–∂ ”©–≥”©—Ö (30+ –º–∏–Ω—É—Ç)

–°–æ–Ω–≥–æ–ª—Ç–æ–æ —Ö—ç–ª—ç—ç—Ä—ç–π! üöÄ
